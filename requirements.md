# myao2 要求仕様書

## 1. プロジェクト概要

### 1.1 プロジェクト名
myao2

### 1.2 目的
Slack上で誰かがコメントした時に、誰も反応しないと寂しいので、それに反応してくれる友達のような存在を提供する。

### 1.3 コンセプト
- **人間のシミュレーション**: 即座に反応するのではなく、適切なタイミングで自然な応答を行う
- **友達のような存在**: お手伝いボットではなく、ワークスペースの一員として振る舞う
- **コンテキスト理解**: ワークスペース、チャンネル、スレッド全体のコンテキストを判断してメッセージを生成

---

## 2. 機能要件

### 2.1 コア機能

#### 2.1.1 応答判定システム
- 誰も反応していないメッセージの検出
- 応答すべきかどうかのLLMによる判定
- 応答タイミングの制御（即座ではなく適切なタイミング）

**応答する場合の判定基準:**
- メッセージが投稿されてからしばらく経過し、誰も返答がなくて困っている/寂しそうな時
- 数人の会話が続いているが、有用なアドバイスができそうな時
- 自分が反応したほうが良いと判断した場合は即座に応答

**応答しない場合の判定基準:**
- 明らかな独り言
- 数人の会話で熱中している場合（割り込むのは適切ではない）

#### 2.1.2 コンテキスト理解
- ワークスペース/チャンネル/スレッドの階層的コンテキスト管理
- 長期記憶・短期記憶の構築と管理
- URL・画像の内容理解

**コンテキスト構築の方針:**
- 応答すべきスレッド、もしくはチャンネルのメッセージ一覧はLLMのmessagesで構築
- それ以外のチャンネルのスレッドに属していないメッセージは、返答生成時の補助会話として別途コンテキストに含める

#### 2.1.3 記憶機能
- 会話履歴の永続化
- 定期的なバックグラウンドでの長期記憶・短期記憶の生成
- 今までの会話履歴を覚えており、それに応じた反応を行う

### 2.2 Slack連携機能

- Appがinviteされたチャンネルを監視
- 起動時にinviteされているチャンネル全ての履歴を取得
- messageイベントを受け取って履歴を更新
- スレッド/チャンネルへの返信

### 2.3 LLM統合

- LiteLLMによる複数プロバイダー対応
- 設定ファイルでLiteLLMのcompletionに渡すdictを指定可能
- 用途別に複数のLLM設定を定義可能（例: 応答生成用、応答判定用）
- ペルソナ設定（名前、性格、口調など）を後から設定可能

### 2.4 外部サービス連携

- わからない話題のWebサーチ
- メッセージ中のURLの情報を取得してコンテキストに含める

---

## 3. 非機能要件

### 3.1 スケーラビリティ
- 10人程度のワークスペース規模に対応
- そこまで活発ではないワークスペースを想定

### 3.2 デプロイ環境
- 本番環境: 自宅のKubernetesクラスタ
- 開発環境: ローカルで起動

### 3.3 拡張性
- 将来的にSlack以外のチャットサービス（Discord等）でも利用できるようなドメイン層設計

---

## 4. 技術仕様

### 4.1 技術スタック

| 項目 | 技術 |
|------|------|
| 言語 | Python |
| パッケージ管理 | uv |
| LLM | LiteLLM |
| Linter | ruff |
| 型チェック | ty |
| 永続化 | SQLite |
| ORM | SQLModel |

### 4.2 アーキテクチャ

- **Dependency Injection (DI)**
- **DDD (Domain-Driven Design)**
- **クリーンアーキテクチャ**

将来的なSlack以外のチャットサービス対応を考慮し、ドメイン層はプラットフォーム非依存とする。

---

## 5. 設定ファイル仕様

設定は `config.yaml` で管理する。機密情報は環境変数経由で注入。

```yaml
# Slack設定
slack:
  bot_token: ${SLACK_BOT_TOKEN}  # 環境変数参照
  app_token: ${SLACK_APP_TOKEN}

# LLM設定（LiteLLMのcompletionに渡すdict）
llm:
  default:
    model: "gpt-4o"
    temperature: 0.7
    max_tokens: 1000
  # 用途別に複数設定可能
  judgment:  # 応答判定用
    model: "gpt-4o-mini"
    temperature: 0.3

# ペルソナ設定
persona:
  name: ""  # 後で設定可能
  system_prompt: ""

# 応答判定設定
response:
  check_interval_seconds: 60  # 判定ループの間隔
  min_wait_seconds: 300  # 最低待機時間（誰も反応しない場合）

# 記憶設定
memory:
  database_path: "./data/memory.db"
  long_term_update_interval_seconds: 3600

# 外部サービス設定
external:
  web_search:
    enabled: false
    # provider設定など
```

**設定の特徴:**
- 環境変数の参照をサポート（`${VAR_NAME}`形式）
- LLM設定は用途別に複数定義可能
- 機密情報は環境変数経由で注入

---

## 6. MVP実装フェーズ

アジャイルのMVP原則に従い、最低限の機能を備えたボットをリリースし、徐々に機能を追加していく。

### Phase 1: 基盤構築

**目標:** プロジェクトの基盤を構築し、最小限のSlack連携とLLM応答を実現

- プロジェクトセットアップ（uv, ruff, ty）
- 設定ファイル基盤（config.yaml読み込み、環境変数展開）
- クリーンアーキテクチャの基本構造
- 基本的なSlack連携（メッセージ受信・送信）
- シンプルなLLM応答（メンション時のみ）

**成果物:** メンションに応答できるシンプルなボット

### Phase 2: コンテキスト管理

**目標:** 会話履歴を考慮した応答を実現

- チャンネル/スレッドの履歴取得
- SQLiteによる会話履歴の永続化
- 基本的なコンテキストを使った応答

**成果物:** 会話の流れを理解して応答できるボット

### Phase 2.5: 非同期化

**目標:** Phase 3「自律的応答」の実現に向けて、アプリケーション全体を asyncio ベースに移行

- asyncio 統合（async def main() + asyncio.run()）
- Slack Bolt 非同期モード（AsyncApp, AsyncSocketModeHandler）
- Protocol の非同期化（async def generate(), async def send_message()）
- LLM クライアント非同期化（litellm.acompletion()）
- リポジトリ非同期化（run_in_executor ラッパー）

**成果物:** 非同期で動作するメンション応答ボット（Phase 3 の並行処理基盤）

### Phase 3: 自律的応答

**目標:** 人間のように適切なタイミングで自律的に応答

- 定期的な応答判定ループ
- 応答すべきかどうかのLLM判定
- 応答タイミングの制御

**成果物:** 誰も反応しないメッセージに自律的に反応するボット

### Phase 4: 記憶システム

**目標:** 長期的な記憶を持つボット

- 長期記憶・短期記憶の実装
- バックグラウンドでの記憶生成
- ワークスペース/チャンネル/スレッドごとの記憶管理

**成果物:** 過去の会話を覚えていて、それに応じた反応ができるボット

### Phase 5: 拡張機能

**目標:** より高度な理解と外部連携

- URL・画像の理解
- Webサーチ機能
- ペルソナのカスタマイズ機能

**成果物:** URLや画像を理解し、必要に応じてWeb検索もできるボット

---

## 7. 用語集

| 用語 | 説明 |
|------|------|
| 長期記憶 | ワークスペース、チャンネル、スレッドの全体的なコンテキストや傾向を要約したもの |
| 短期記憶 | 最近の会話履歴や直近のやり取りの詳細 |
| 応答判定 | メッセージに対して応答すべきかどうかをLLMで判断するプロセス |
| ペルソナ | ボットの性格、口調、名前などの設定 |
